{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b997511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12f624a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ab6a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "weights= models.MNASNet1_3_Weights.DEFAULT.DEFAULT\n",
    "\n",
    "transform= weights.transforms()\n",
    "print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f96f738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=transform.mean\n",
    "std=transform.std\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a488a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= datasets.ImageFolder(root= r'D:\\ASL_Project\\augmented_dataset2', transform= train_transform)\n",
    "\n",
    "label_map = {'rejected': 0, 'approved': 1}\n",
    "\n",
    "train_dataset.targets = [\n",
    "    label_map[train_dataset.classes[label]]\n",
    "    for label in train_dataset.targets\n",
    "]\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size=16 , shuffle= True, num_workers= 4, pin_memory= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0df20a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset= datasets.ImageFolder(root= r'D:\\ASL_Project\\dataset', transform= transform)\n",
    "\n",
    "label_map = {'rejected': 0, 'approved': 1}\n",
    "\n",
    "test_dataset.targets = [\n",
    "    label_map[test_dataset.classes[label]]\n",
    "    for label in test_dataset.targets\n",
    "]\n",
    "\n",
    "test_loader= DataLoader(test_dataset, batch_size=16 , shuffle= True, num_workers= 4, pin_memory= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b83adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= models.mnasnet1_3(weights= weights)\n",
    "model= model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37414b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 40, 112, 112]           1,080\n",
      "       BatchNorm2d-2         [-1, 40, 112, 112]              80\n",
      "              ReLU-3         [-1, 40, 112, 112]               0\n",
      "            Conv2d-4         [-1, 40, 112, 112]             360\n",
      "       BatchNorm2d-5         [-1, 40, 112, 112]              80\n",
      "              ReLU-6         [-1, 40, 112, 112]               0\n",
      "            Conv2d-7         [-1, 24, 112, 112]             960\n",
      "       BatchNorm2d-8         [-1, 24, 112, 112]              48\n",
      "            Conv2d-9         [-1, 72, 112, 112]           1,728\n",
      "      BatchNorm2d-10         [-1, 72, 112, 112]             144\n",
      "             ReLU-11         [-1, 72, 112, 112]               0\n",
      "           Conv2d-12           [-1, 72, 56, 56]             648\n",
      "      BatchNorm2d-13           [-1, 72, 56, 56]             144\n",
      "             ReLU-14           [-1, 72, 56, 56]               0\n",
      "           Conv2d-15           [-1, 32, 56, 56]           2,304\n",
      "      BatchNorm2d-16           [-1, 32, 56, 56]              64\n",
      "_InvertedResidual-17           [-1, 32, 56, 56]               0\n",
      "           Conv2d-18           [-1, 96, 56, 56]           3,072\n",
      "      BatchNorm2d-19           [-1, 96, 56, 56]             192\n",
      "             ReLU-20           [-1, 96, 56, 56]               0\n",
      "           Conv2d-21           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-22           [-1, 96, 56, 56]             192\n",
      "             ReLU-23           [-1, 96, 56, 56]               0\n",
      "           Conv2d-24           [-1, 32, 56, 56]           3,072\n",
      "      BatchNorm2d-25           [-1, 32, 56, 56]              64\n",
      "_InvertedResidual-26           [-1, 32, 56, 56]               0\n",
      "           Conv2d-27           [-1, 96, 56, 56]           3,072\n",
      "      BatchNorm2d-28           [-1, 96, 56, 56]             192\n",
      "             ReLU-29           [-1, 96, 56, 56]               0\n",
      "           Conv2d-30           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-31           [-1, 96, 56, 56]             192\n",
      "             ReLU-32           [-1, 96, 56, 56]               0\n",
      "           Conv2d-33           [-1, 32, 56, 56]           3,072\n",
      "      BatchNorm2d-34           [-1, 32, 56, 56]              64\n",
      "_InvertedResidual-35           [-1, 32, 56, 56]               0\n",
      "           Conv2d-36           [-1, 96, 56, 56]           3,072\n",
      "      BatchNorm2d-37           [-1, 96, 56, 56]             192\n",
      "             ReLU-38           [-1, 96, 56, 56]               0\n",
      "           Conv2d-39           [-1, 96, 28, 28]           2,400\n",
      "      BatchNorm2d-40           [-1, 96, 28, 28]             192\n",
      "             ReLU-41           [-1, 96, 28, 28]               0\n",
      "           Conv2d-42           [-1, 56, 28, 28]           5,376\n",
      "      BatchNorm2d-43           [-1, 56, 28, 28]             112\n",
      "_InvertedResidual-44           [-1, 56, 28, 28]               0\n",
      "           Conv2d-45          [-1, 168, 28, 28]           9,408\n",
      "      BatchNorm2d-46          [-1, 168, 28, 28]             336\n",
      "             ReLU-47          [-1, 168, 28, 28]               0\n",
      "           Conv2d-48          [-1, 168, 28, 28]           4,200\n",
      "      BatchNorm2d-49          [-1, 168, 28, 28]             336\n",
      "             ReLU-50          [-1, 168, 28, 28]               0\n",
      "           Conv2d-51           [-1, 56, 28, 28]           9,408\n",
      "      BatchNorm2d-52           [-1, 56, 28, 28]             112\n",
      "_InvertedResidual-53           [-1, 56, 28, 28]               0\n",
      "           Conv2d-54          [-1, 168, 28, 28]           9,408\n",
      "      BatchNorm2d-55          [-1, 168, 28, 28]             336\n",
      "             ReLU-56          [-1, 168, 28, 28]               0\n",
      "           Conv2d-57          [-1, 168, 28, 28]           4,200\n",
      "      BatchNorm2d-58          [-1, 168, 28, 28]             336\n",
      "             ReLU-59          [-1, 168, 28, 28]               0\n",
      "           Conv2d-60           [-1, 56, 28, 28]           9,408\n",
      "      BatchNorm2d-61           [-1, 56, 28, 28]             112\n",
      "_InvertedResidual-62           [-1, 56, 28, 28]               0\n",
      "           Conv2d-63          [-1, 336, 28, 28]          18,816\n",
      "      BatchNorm2d-64          [-1, 336, 28, 28]             672\n",
      "             ReLU-65          [-1, 336, 28, 28]               0\n",
      "           Conv2d-66          [-1, 336, 14, 14]           8,400\n",
      "      BatchNorm2d-67          [-1, 336, 14, 14]             672\n",
      "             ReLU-68          [-1, 336, 14, 14]               0\n",
      "           Conv2d-69          [-1, 104, 14, 14]          34,944\n",
      "      BatchNorm2d-70          [-1, 104, 14, 14]             208\n",
      "_InvertedResidual-71          [-1, 104, 14, 14]               0\n",
      "           Conv2d-72          [-1, 624, 14, 14]          64,896\n",
      "      BatchNorm2d-73          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-74          [-1, 624, 14, 14]               0\n",
      "           Conv2d-75          [-1, 624, 14, 14]          15,600\n",
      "      BatchNorm2d-76          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-77          [-1, 624, 14, 14]               0\n",
      "           Conv2d-78          [-1, 104, 14, 14]          64,896\n",
      "      BatchNorm2d-79          [-1, 104, 14, 14]             208\n",
      "_InvertedResidual-80          [-1, 104, 14, 14]               0\n",
      "           Conv2d-81          [-1, 624, 14, 14]          64,896\n",
      "      BatchNorm2d-82          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-83          [-1, 624, 14, 14]               0\n",
      "           Conv2d-84          [-1, 624, 14, 14]          15,600\n",
      "      BatchNorm2d-85          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-86          [-1, 624, 14, 14]               0\n",
      "           Conv2d-87          [-1, 104, 14, 14]          64,896\n",
      "      BatchNorm2d-88          [-1, 104, 14, 14]             208\n",
      "_InvertedResidual-89          [-1, 104, 14, 14]               0\n",
      "           Conv2d-90          [-1, 624, 14, 14]          64,896\n",
      "      BatchNorm2d-91          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-92          [-1, 624, 14, 14]               0\n",
      "           Conv2d-93          [-1, 624, 14, 14]           5,616\n",
      "      BatchNorm2d-94          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-95          [-1, 624, 14, 14]               0\n",
      "           Conv2d-96          [-1, 128, 14, 14]          79,872\n",
      "      BatchNorm2d-97          [-1, 128, 14, 14]             256\n",
      "_InvertedResidual-98          [-1, 128, 14, 14]               0\n",
      "           Conv2d-99          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-100          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-101          [-1, 768, 14, 14]               0\n",
      "          Conv2d-102          [-1, 768, 14, 14]           6,912\n",
      "     BatchNorm2d-103          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-104          [-1, 768, 14, 14]               0\n",
      "          Conv2d-105          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-106          [-1, 128, 14, 14]             256\n",
      "_InvertedResidual-107          [-1, 128, 14, 14]               0\n",
      "          Conv2d-108          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-109          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-110          [-1, 768, 14, 14]               0\n",
      "          Conv2d-111            [-1, 768, 7, 7]          19,200\n",
      "     BatchNorm2d-112            [-1, 768, 7, 7]           1,536\n",
      "            ReLU-113            [-1, 768, 7, 7]               0\n",
      "          Conv2d-114            [-1, 248, 7, 7]         190,464\n",
      "     BatchNorm2d-115            [-1, 248, 7, 7]             496\n",
      "_InvertedResidual-116            [-1, 248, 7, 7]               0\n",
      "          Conv2d-117           [-1, 1488, 7, 7]         369,024\n",
      "     BatchNorm2d-118           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-119           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-120           [-1, 1488, 7, 7]          37,200\n",
      "     BatchNorm2d-121           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-122           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-123            [-1, 248, 7, 7]         369,024\n",
      "     BatchNorm2d-124            [-1, 248, 7, 7]             496\n",
      "_InvertedResidual-125            [-1, 248, 7, 7]               0\n",
      "          Conv2d-126           [-1, 1488, 7, 7]         369,024\n",
      "     BatchNorm2d-127           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-128           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-129           [-1, 1488, 7, 7]          37,200\n",
      "     BatchNorm2d-130           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-131           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-132            [-1, 248, 7, 7]         369,024\n",
      "     BatchNorm2d-133            [-1, 248, 7, 7]             496\n",
      "_InvertedResidual-134            [-1, 248, 7, 7]               0\n",
      "          Conv2d-135           [-1, 1488, 7, 7]         369,024\n",
      "     BatchNorm2d-136           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-137           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-138           [-1, 1488, 7, 7]          37,200\n",
      "     BatchNorm2d-139           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-140           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-141            [-1, 248, 7, 7]         369,024\n",
      "     BatchNorm2d-142            [-1, 248, 7, 7]             496\n",
      "_InvertedResidual-143            [-1, 248, 7, 7]               0\n",
      "          Conv2d-144           [-1, 1488, 7, 7]         369,024\n",
      "     BatchNorm2d-145           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-146           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-147           [-1, 1488, 7, 7]          13,392\n",
      "     BatchNorm2d-148           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-149           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-150            [-1, 416, 7, 7]         619,008\n",
      "     BatchNorm2d-151            [-1, 416, 7, 7]             832\n",
      "_InvertedResidual-152            [-1, 416, 7, 7]               0\n",
      "          Conv2d-153           [-1, 1280, 7, 7]         532,480\n",
      "     BatchNorm2d-154           [-1, 1280, 7, 7]           2,560\n",
      "            ReLU-155           [-1, 1280, 7, 7]               0\n",
      "         Dropout-156                 [-1, 1280]               0\n",
      "          Linear-157                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 6,282,256\n",
      "Trainable params: 6,282,256\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 166.00\n",
      "Params size (MB): 23.96\n",
      "Estimated Total Size (MB): 190.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6108d4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNASNet(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "    (4): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (8): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(96, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(56, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(56, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(168, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "          (4): BatchNorm2d(168, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(168, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(56, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(56, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(168, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "          (4): BatchNorm2d(168, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(168, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(56, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(336, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(336, 336, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=336, bias=False)\n",
       "          (4): BatchNorm2d(336, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(336, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(104, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(624, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(624, 624, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=624, bias=False)\n",
       "          (4): BatchNorm2d(624, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(624, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(104, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(624, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(624, 624, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=624, bias=False)\n",
       "          (4): BatchNorm2d(624, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(624, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(104, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(624, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(624, 624, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=624, bias=False)\n",
       "          (4): BatchNorm2d(624, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(624, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (4): BatchNorm2d(768, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(768, 768, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=768, bias=False)\n",
       "          (4): BatchNorm2d(768, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(768, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(248, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(248, 1488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1488, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1488, 1488, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1488, bias=False)\n",
       "          (4): BatchNorm2d(1488, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(1488, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(248, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(248, 1488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1488, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1488, 1488, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1488, bias=False)\n",
       "          (4): BatchNorm2d(1488, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(1488, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(248, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(248, 1488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1488, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1488, 1488, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1488, bias=False)\n",
       "          (4): BatchNorm2d(1488, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(1488, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(248, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(248, 1488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1488, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1488, 1488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1488, bias=False)\n",
       "          (4): BatchNorm2d(1488, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(1488, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(416, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Conv2d(416, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1280, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "model.classifier= nn.Linear(1280, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef559e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 40, 112, 112]           1,080\n",
      "       BatchNorm2d-2         [-1, 40, 112, 112]              80\n",
      "              ReLU-3         [-1, 40, 112, 112]               0\n",
      "            Conv2d-4         [-1, 40, 112, 112]             360\n",
      "       BatchNorm2d-5         [-1, 40, 112, 112]              80\n",
      "              ReLU-6         [-1, 40, 112, 112]               0\n",
      "            Conv2d-7         [-1, 24, 112, 112]             960\n",
      "       BatchNorm2d-8         [-1, 24, 112, 112]              48\n",
      "            Conv2d-9         [-1, 72, 112, 112]           1,728\n",
      "      BatchNorm2d-10         [-1, 72, 112, 112]             144\n",
      "             ReLU-11         [-1, 72, 112, 112]               0\n",
      "           Conv2d-12           [-1, 72, 56, 56]             648\n",
      "      BatchNorm2d-13           [-1, 72, 56, 56]             144\n",
      "             ReLU-14           [-1, 72, 56, 56]               0\n",
      "           Conv2d-15           [-1, 32, 56, 56]           2,304\n",
      "      BatchNorm2d-16           [-1, 32, 56, 56]              64\n",
      "_InvertedResidual-17           [-1, 32, 56, 56]               0\n",
      "           Conv2d-18           [-1, 96, 56, 56]           3,072\n",
      "      BatchNorm2d-19           [-1, 96, 56, 56]             192\n",
      "             ReLU-20           [-1, 96, 56, 56]               0\n",
      "           Conv2d-21           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-22           [-1, 96, 56, 56]             192\n",
      "             ReLU-23           [-1, 96, 56, 56]               0\n",
      "           Conv2d-24           [-1, 32, 56, 56]           3,072\n",
      "      BatchNorm2d-25           [-1, 32, 56, 56]              64\n",
      "_InvertedResidual-26           [-1, 32, 56, 56]               0\n",
      "           Conv2d-27           [-1, 96, 56, 56]           3,072\n",
      "      BatchNorm2d-28           [-1, 96, 56, 56]             192\n",
      "             ReLU-29           [-1, 96, 56, 56]               0\n",
      "           Conv2d-30           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-31           [-1, 96, 56, 56]             192\n",
      "             ReLU-32           [-1, 96, 56, 56]               0\n",
      "           Conv2d-33           [-1, 32, 56, 56]           3,072\n",
      "      BatchNorm2d-34           [-1, 32, 56, 56]              64\n",
      "_InvertedResidual-35           [-1, 32, 56, 56]               0\n",
      "           Conv2d-36           [-1, 96, 56, 56]           3,072\n",
      "      BatchNorm2d-37           [-1, 96, 56, 56]             192\n",
      "             ReLU-38           [-1, 96, 56, 56]               0\n",
      "           Conv2d-39           [-1, 96, 28, 28]           2,400\n",
      "      BatchNorm2d-40           [-1, 96, 28, 28]             192\n",
      "             ReLU-41           [-1, 96, 28, 28]               0\n",
      "           Conv2d-42           [-1, 56, 28, 28]           5,376\n",
      "      BatchNorm2d-43           [-1, 56, 28, 28]             112\n",
      "_InvertedResidual-44           [-1, 56, 28, 28]               0\n",
      "           Conv2d-45          [-1, 168, 28, 28]           9,408\n",
      "      BatchNorm2d-46          [-1, 168, 28, 28]             336\n",
      "             ReLU-47          [-1, 168, 28, 28]               0\n",
      "           Conv2d-48          [-1, 168, 28, 28]           4,200\n",
      "      BatchNorm2d-49          [-1, 168, 28, 28]             336\n",
      "             ReLU-50          [-1, 168, 28, 28]               0\n",
      "           Conv2d-51           [-1, 56, 28, 28]           9,408\n",
      "      BatchNorm2d-52           [-1, 56, 28, 28]             112\n",
      "_InvertedResidual-53           [-1, 56, 28, 28]               0\n",
      "           Conv2d-54          [-1, 168, 28, 28]           9,408\n",
      "      BatchNorm2d-55          [-1, 168, 28, 28]             336\n",
      "             ReLU-56          [-1, 168, 28, 28]               0\n",
      "           Conv2d-57          [-1, 168, 28, 28]           4,200\n",
      "      BatchNorm2d-58          [-1, 168, 28, 28]             336\n",
      "             ReLU-59          [-1, 168, 28, 28]               0\n",
      "           Conv2d-60           [-1, 56, 28, 28]           9,408\n",
      "      BatchNorm2d-61           [-1, 56, 28, 28]             112\n",
      "_InvertedResidual-62           [-1, 56, 28, 28]               0\n",
      "           Conv2d-63          [-1, 336, 28, 28]          18,816\n",
      "      BatchNorm2d-64          [-1, 336, 28, 28]             672\n",
      "             ReLU-65          [-1, 336, 28, 28]               0\n",
      "           Conv2d-66          [-1, 336, 14, 14]           8,400\n",
      "      BatchNorm2d-67          [-1, 336, 14, 14]             672\n",
      "             ReLU-68          [-1, 336, 14, 14]               0\n",
      "           Conv2d-69          [-1, 104, 14, 14]          34,944\n",
      "      BatchNorm2d-70          [-1, 104, 14, 14]             208\n",
      "_InvertedResidual-71          [-1, 104, 14, 14]               0\n",
      "           Conv2d-72          [-1, 624, 14, 14]          64,896\n",
      "      BatchNorm2d-73          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-74          [-1, 624, 14, 14]               0\n",
      "           Conv2d-75          [-1, 624, 14, 14]          15,600\n",
      "      BatchNorm2d-76          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-77          [-1, 624, 14, 14]               0\n",
      "           Conv2d-78          [-1, 104, 14, 14]          64,896\n",
      "      BatchNorm2d-79          [-1, 104, 14, 14]             208\n",
      "_InvertedResidual-80          [-1, 104, 14, 14]               0\n",
      "           Conv2d-81          [-1, 624, 14, 14]          64,896\n",
      "      BatchNorm2d-82          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-83          [-1, 624, 14, 14]               0\n",
      "           Conv2d-84          [-1, 624, 14, 14]          15,600\n",
      "      BatchNorm2d-85          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-86          [-1, 624, 14, 14]               0\n",
      "           Conv2d-87          [-1, 104, 14, 14]          64,896\n",
      "      BatchNorm2d-88          [-1, 104, 14, 14]             208\n",
      "_InvertedResidual-89          [-1, 104, 14, 14]               0\n",
      "           Conv2d-90          [-1, 624, 14, 14]          64,896\n",
      "      BatchNorm2d-91          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-92          [-1, 624, 14, 14]               0\n",
      "           Conv2d-93          [-1, 624, 14, 14]           5,616\n",
      "      BatchNorm2d-94          [-1, 624, 14, 14]           1,248\n",
      "             ReLU-95          [-1, 624, 14, 14]               0\n",
      "           Conv2d-96          [-1, 128, 14, 14]          79,872\n",
      "      BatchNorm2d-97          [-1, 128, 14, 14]             256\n",
      "_InvertedResidual-98          [-1, 128, 14, 14]               0\n",
      "           Conv2d-99          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-100          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-101          [-1, 768, 14, 14]               0\n",
      "          Conv2d-102          [-1, 768, 14, 14]           6,912\n",
      "     BatchNorm2d-103          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-104          [-1, 768, 14, 14]               0\n",
      "          Conv2d-105          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-106          [-1, 128, 14, 14]             256\n",
      "_InvertedResidual-107          [-1, 128, 14, 14]               0\n",
      "          Conv2d-108          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-109          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-110          [-1, 768, 14, 14]               0\n",
      "          Conv2d-111            [-1, 768, 7, 7]          19,200\n",
      "     BatchNorm2d-112            [-1, 768, 7, 7]           1,536\n",
      "            ReLU-113            [-1, 768, 7, 7]               0\n",
      "          Conv2d-114            [-1, 248, 7, 7]         190,464\n",
      "     BatchNorm2d-115            [-1, 248, 7, 7]             496\n",
      "_InvertedResidual-116            [-1, 248, 7, 7]               0\n",
      "          Conv2d-117           [-1, 1488, 7, 7]         369,024\n",
      "     BatchNorm2d-118           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-119           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-120           [-1, 1488, 7, 7]          37,200\n",
      "     BatchNorm2d-121           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-122           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-123            [-1, 248, 7, 7]         369,024\n",
      "     BatchNorm2d-124            [-1, 248, 7, 7]             496\n",
      "_InvertedResidual-125            [-1, 248, 7, 7]               0\n",
      "          Conv2d-126           [-1, 1488, 7, 7]         369,024\n",
      "     BatchNorm2d-127           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-128           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-129           [-1, 1488, 7, 7]          37,200\n",
      "     BatchNorm2d-130           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-131           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-132            [-1, 248, 7, 7]         369,024\n",
      "     BatchNorm2d-133            [-1, 248, 7, 7]             496\n",
      "_InvertedResidual-134            [-1, 248, 7, 7]               0\n",
      "          Conv2d-135           [-1, 1488, 7, 7]         369,024\n",
      "     BatchNorm2d-136           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-137           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-138           [-1, 1488, 7, 7]          37,200\n",
      "     BatchNorm2d-139           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-140           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-141            [-1, 248, 7, 7]         369,024\n",
      "     BatchNorm2d-142            [-1, 248, 7, 7]             496\n",
      "_InvertedResidual-143            [-1, 248, 7, 7]               0\n",
      "          Conv2d-144           [-1, 1488, 7, 7]         369,024\n",
      "     BatchNorm2d-145           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-146           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-147           [-1, 1488, 7, 7]          13,392\n",
      "     BatchNorm2d-148           [-1, 1488, 7, 7]           2,976\n",
      "            ReLU-149           [-1, 1488, 7, 7]               0\n",
      "          Conv2d-150            [-1, 416, 7, 7]         619,008\n",
      "     BatchNorm2d-151            [-1, 416, 7, 7]             832\n",
      "_InvertedResidual-152            [-1, 416, 7, 7]               0\n",
      "          Conv2d-153           [-1, 1280, 7, 7]         532,480\n",
      "     BatchNorm2d-154           [-1, 1280, 7, 7]           2,560\n",
      "            ReLU-155           [-1, 1280, 7, 7]               0\n",
      "          Linear-156                    [-1, 1]           1,281\n",
      "================================================================\n",
      "Total params: 5,002,537\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 5,001,256\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 165.99\n",
      "Params size (MB): 19.08\n",
      "Estimated Total Size (MB): 185.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54cfe3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn= nn.BCEWithLogitsLoss()\n",
    "optimizer= torch.optim.AdamW(model.parameters(), lr= 0.001)\n",
    "scheduler= torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience= 3, factor= 0.5)\n",
    "\n",
    "def training(dataloader, model, loss_fn, optimizer, scheduler=None):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.float().unsqueeze(1).to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        probs = torch.sigmoid(pred)\n",
    "        preds = (probs > 0.5).int()\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    all_preds = torch.tensor(all_preds).view(-1)\n",
    "    all_labels = torch.tensor(all_labels).view(-1)\n",
    "\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "    print(f\"Train Loss: {avg_loss:.4f} | Accuracy: {accuracy:.4f} | F1 Score: {f1:.4f}\")\n",
    "    \n",
    "\n",
    "\n",
    "def testing(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.float().unsqueeze(1).to(device)\n",
    "\n",
    "            pred = model(X)         \n",
    "            loss = loss_fn(pred, y) \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "\n",
    "            probs = torch.sigmoid(pred)\n",
    "            preds = (probs > 0.5).int()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    all_preds = torch.tensor(all_preds).view(-1)\n",
    "    all_labels = torch.tensor(all_labels).view(-1)\n",
    "\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f} | Accuracy: {accuracy:.4f} | F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f7d902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.3594 | Accuracy: 0.8477 | F1 Score: 0.6465\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.5407 | Accuracy: 0.7546 | F1: 0.1681\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 2/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.2274 | Accuracy: 0.9217 | F1 Score: 0.8454\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3557 | Accuracy: 0.8420 | F1: 0.5870\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 3/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1971 | Accuracy: 0.9256 | F1 Score: 0.8588\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.5689 | Accuracy: 0.8016 | F1: 0.4198\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 4/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1750 | Accuracy: 0.9339 | F1 Score: 0.8742\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.5557 | Accuracy: 0.8146 | F1: 0.4779\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 5/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1470 | Accuracy: 0.9508 | F1 Score: 0.9076\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.6264 | Accuracy: 0.8081 | F1: 0.4494\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 6/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1421 | Accuracy: 0.9521 | F1 Score: 0.9097\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.5487 | Accuracy: 0.8264 | F1: 0.5267\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 7/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1343 | Accuracy: 0.9574 | F1 Score: 0.9197\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.5393 | Accuracy: 0.8290 | F1: 0.5371\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 8/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1284 | Accuracy: 0.9552 | F1 Score: 0.9158\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.4492 | Accuracy: 0.8473 | F1: 0.6061\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 9/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1199 | Accuracy: 0.9569 | F1 Score: 0.9196\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.4007 | Accuracy: 0.8616 | F1: 0.6558\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 10/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1168 | Accuracy: 0.9621 | F1 Score: 0.9293\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.5089 | Accuracy: 0.8433 | F1: 0.5918\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 11/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1124 | Accuracy: 0.9600 | F1 Score: 0.9242\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3666 | Accuracy: 0.8655 | F1: 0.6688\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 12/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1203 | Accuracy: 0.9587 | F1 Score: 0.9223\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3527 | Accuracy: 0.8708 | F1: 0.6857\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 13/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1102 | Accuracy: 0.9600 | F1 Score: 0.9256\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3930 | Accuracy: 0.8629 | F1: 0.6602\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 14/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1039 | Accuracy: 0.9661 | F1 Score: 0.9369\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.4341 | Accuracy: 0.8590 | F1: 0.6471\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 15/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1019 | Accuracy: 0.9630 | F1 Score: 0.9307\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3905 | Accuracy: 0.8681 | F1: 0.6773\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 16/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.1023 | Accuracy: 0.9678 | F1 Score: 0.9396\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3294 | Accuracy: 0.8786 | F1: 0.7103\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 17/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0954 | Accuracy: 0.9669 | F1 Score: 0.9382\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3263 | Accuracy: 0.8799 | F1: 0.7143\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 18/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0891 | Accuracy: 0.9695 | F1 Score: 0.9430\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3866 | Accuracy: 0.8695 | F1: 0.6815\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 19/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0949 | Accuracy: 0.9708 | F1 Score: 0.9455\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3185 | Accuracy: 0.8838 | F1: 0.7262\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 20/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0906 | Accuracy: 0.9713 | F1 Score: 0.9463\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3108 | Accuracy: 0.8877 | F1: 0.7378\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 21/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0782 | Accuracy: 0.9756 | F1 Score: 0.9545\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2750 | Accuracy: 0.9021 | F1: 0.7788\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 22/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0849 | Accuracy: 0.9704 | F1 Score: 0.9452\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3650 | Accuracy: 0.8812 | F1: 0.7183\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 23/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0844 | Accuracy: 0.9717 | F1 Score: 0.9471\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2891 | Accuracy: 0.8956 | F1: 0.7605\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 24/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0862 | Accuracy: 0.9713 | F1 Score: 0.9464\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2784 | Accuracy: 0.9008 | F1: 0.7751\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 25/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0852 | Accuracy: 0.9682 | F1 Score: 0.9408\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.3540 | Accuracy: 0.8864 | F1: 0.7339\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 26/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0764 | Accuracy: 0.9769 | F1 Score: 0.9569\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2883 | Accuracy: 0.8969 | F1: 0.7642\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 27/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0798 | Accuracy: 0.9730 | F1 Score: 0.9497\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2226 | Accuracy: 0.9191 | F1: 0.8239\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 28/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0788 | Accuracy: 0.9743 | F1 Score: 0.9523\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2432 | Accuracy: 0.9060 | F1: 0.7895\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 29/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0759 | Accuracy: 0.9769 | F1 Score: 0.9572\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2189 | Accuracy: 0.9178 | F1: 0.8205\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 30/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0839 | Accuracy: 0.9726 | F1 Score: 0.9492\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2117 | Accuracy: 0.9178 | F1: 0.8205\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 31/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0758 | Accuracy: 0.9748 | F1 Score: 0.9530\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2003 | Accuracy: 0.9191 | F1: 0.8239\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 32/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0876 | Accuracy: 0.9695 | F1 Score: 0.9428\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2170 | Accuracy: 0.9151 | F1: 0.8138\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 33/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0761 | Accuracy: 0.9735 | F1 Score: 0.9504\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2086 | Accuracy: 0.9151 | F1: 0.8138\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 34/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0740 | Accuracy: 0.9743 | F1 Score: 0.9525\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2573 | Accuracy: 0.9021 | F1: 0.7788\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 35/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0744 | Accuracy: 0.9778 | F1 Score: 0.9586\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2195 | Accuracy: 0.9151 | F1: 0.8138\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 36/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0699 | Accuracy: 0.9769 | F1 Score: 0.9573\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.1881 | Accuracy: 0.9230 | F1: 0.8338\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 37/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0646 | Accuracy: 0.9765 | F1 Score: 0.9564\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2100 | Accuracy: 0.9191 | F1: 0.8239\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 38/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0646 | Accuracy: 0.9809 | F1 Score: 0.9645\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.1996 | Accuracy: 0.9191 | F1: 0.8239\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 39/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0726 | Accuracy: 0.9778 | F1 Score: 0.9588\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.2084 | Accuracy: 0.9178 | F1: 0.8205\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 40/40:\n",
      "--------------------------------------------------\n",
      "Train Loss: 0.0867 | Accuracy: 0.9708 | F1 Score: 0.9455\n",
      "--------------------------------------------------\n",
      "Test Loss: 0.1660 | Accuracy: 0.9282 | F1: 0.8476\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs=40\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}:\")\n",
    "    print(\"-\"*50)\n",
    "    training(train_loader, model, loss_fn, optimizer, scheduler)\n",
    "    print(\"-\"*50)\n",
    "    testing(test_loader, model, loss_fn)\n",
    "    print(\"-\"*50)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c86dea0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[558   1]\n",
      " [ 54 153]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_confusion_matrix(dataloader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.float().to(device)\n",
    "\n",
    "            pred = model(X)                 \n",
    "            probs = torch.sigmoid(pred)     \n",
    "            preds = (probs > 0.5).int()    \n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    \n",
    "    all_preds = np.array(all_preds).reshape(-1)\n",
    "    all_labels = np.array(all_labels).reshape(-1)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Optional: pretty heatmap\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Approved','Rejected'],\n",
    "                yticklabels=['Approved','Rejected'])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    \n",
    "print_confusion_matrix(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9913c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
