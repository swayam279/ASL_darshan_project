{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e98273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4f049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetterboxPad:\n",
    "    \"\"\"\n",
    "    Pads images with black borders to make them square.\n",
    "    This prevents distortion when resizing.\n",
    "    \"\"\"\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        max_dim = max(w, h)\n",
    "        padding = ImageOps.pad(img, (max_dim, max_dim), color=\"black\", centering=(0.5, 0.5))\n",
    "        return padding\n",
    "\n",
    "augment_transform= v2.Compose([\n",
    "    LetterboxPad(),\n",
    "    v2.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "    v2.Resize(232),\n",
    "    v2.CenterCrop(224),\n",
    "    v2.RandomHorizontalFlip(0.2),\n",
    "    # v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    v2.RandomGrayscale(0.2),\n",
    "    v2.RandomRotation(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f65a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing the approved folder:   0%|          | 0/559 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing the approved folder: 100%|██████████| 559/559 [00:21<00:00, 26.06it/s]\n",
      "processing the rejected folder: 100%|██████████| 207/207 [00:23<00:00,  8.67it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_root= r\"D:\\ASL_Project\\dataset\"\n",
    "augmented_dataset_root= r\"D:\\ASL_Project\\augmented_dataset2\"\n",
    "\n",
    "num_augmentations= 2\n",
    "os.makedirs(augmented_dataset_root, exist_ok= True)\n",
    "classes= [\"approved\", \"rejected\"]\n",
    "\n",
    "for cls in classes:\n",
    "    input_dir= os.path.join(dataset_root, cls)\n",
    "    output_dir= os.path.join(augmented_dataset_root, cls)\n",
    "    os.makedirs(output_dir, exist_ok= True)\n",
    "    \n",
    "    image_files= os.listdir(input_dir)\n",
    "    \n",
    "    for img_name in tqdm(image_files, desc=f\"processing the {cls} folder\"):\n",
    "        img_path= os.path.join(input_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            image= Image.open(img_path).convert(\"RGB\")\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        base_name= os.path.splitext(img_name)[0]\n",
    "        \n",
    "        processed_original= v2.Compose([\n",
    "            v2.Resize(232),\n",
    "            v2.CenterCrop(224)\n",
    "        ])(image)\n",
    "        \n",
    "        processed_original.save(os.path.join(output_dir, f\"{base_name}_original.jpg\"))\n",
    "        \n",
    "        for i in range(num_augmentations):\n",
    "            augmented_image= augment_transform(image)\n",
    "            save_name=f\"{base_name}_augmented{i}.jpg\"\n",
    "            augmented_image.save(os.path.join(output_dir, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5db3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
